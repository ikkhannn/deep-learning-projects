{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"housing.csv\", delim_whitespace=True, header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(16,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='Adam',loss='mean_squared_error',metrics=['accuracy'])\n",
    "    \n",
    "    #model.fit(partial_x_train,partial_y_train,epochs=5,validation_data=(x_val,y_val))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -41.87 (33.17) MSE\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: -25.21 (25.24) MSE\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deeper_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(16,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(8,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='Adam',loss='mean_squared_error',metrics=['accuracy'])\n",
    "    \n",
    "    #model.fit(partial_x_train,partial_y_train,epochs=5,validation_data=(x_val,y_val))\n",
    "    return model\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=deeper_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider: -21.25 (21.83) MSE\n"
     ]
    }
   ],
   "source": [
    "def wider_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(20,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='Adam',loss='mean_squared_error',metrics=['accuracy'])\n",
    "    \n",
    "    #model.fit(partial_x_train,partial_y_train,epochs=5,validation_data=(x_val,y_val))\n",
    "    return model\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider: -28.18 (24.59) MSE\n"
     ]
    }
   ],
   "source": [
    "def overfit_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(20,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='Adam',loss='mean_squared_error',metrics=['accuracy'])\n",
    "    \n",
    "    #model.fit(partial_x_train,partial_y_train,epochs=5,validation_data=(x_val,y_val))\n",
    "    return model\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=overfit_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider: -21.40 (28.14) MSE\n"
     ]
    }
   ],
   "source": [
    "def tuned_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(32,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='rmsprop',loss='mean_squared_error',metrics=['accuracy'])\n",
    "    \n",
    "    #model.fit(partial_x_train,partial_y_train,epochs=5,validation_data=(x_val,y_val))\n",
    "    return model\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=tuned_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 314 samples, validate on 25 samples\n",
      "Epoch 1/300\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 28125.8407 - acc: 0.0000e+00 - val_loss: 15272.2891 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 15829.1128 - acc: 0.0032 - val_loss: 7737.0576 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 8990.2087 - acc: 0.0000e+00 - val_loss: 4661.7349 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 5933.9321 - acc: 0.0000e+00 - val_loss: 3519.5593 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 4418.1412 - acc: 0.0000e+00 - val_loss: 2710.0247 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 3281.7666 - acc: 0.0000e+00 - val_loss: 1940.9603 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 2393.4864 - acc: 0.0000e+00 - val_loss: 1385.5383 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 1763.0163 - acc: 0.0000e+00 - val_loss: 1060.2720 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 1362.6551 - acc: 0.0032 - val_loss: 859.0353 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 1069.0090 - acc: 0.0000e+00 - val_loss: 726.3724 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 858.9057 - acc: 0.0000e+00 - val_loss: 640.7270 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "314/314 [==============================] - 0s 101us/step - loss: 721.7559 - acc: 0.0000e+00 - val_loss: 584.1418 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 622.4366 - acc: 0.0032 - val_loss: 542.5051 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 549.7801 - acc: 0.0000e+00 - val_loss: 511.4502 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 491.2454 - acc: 0.0000e+00 - val_loss: 486.4976 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 449.2885 - acc: 0.0000e+00 - val_loss: 465.0800 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 417.2830 - acc: 0.0000e+00 - val_loss: 444.5244 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 389.8789 - acc: 0.0000e+00 - val_loss: 424.8453 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 366.8391 - acc: 0.0032 - val_loss: 407.1273 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 348.4199 - acc: 0.0000e+00 - val_loss: 393.0403 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 329.7699 - acc: 0.0032 - val_loss: 378.9337 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "314/314 [==============================] - 0s 89us/step - loss: 315.8625 - acc: 0.0000e+00 - val_loss: 365.3044 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 302.7263 - acc: 0.0032 - val_loss: 354.6088 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 290.0552 - acc: 0.0000e+00 - val_loss: 343.3662 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 278.0020 - acc: 0.0000e+00 - val_loss: 331.0634 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 267.2827 - acc: 0.0032 - val_loss: 316.5341 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 255.5434 - acc: 0.0032 - val_loss: 307.9189 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 246.7656 - acc: 0.0000e+00 - val_loss: 300.0081 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "314/314 [==============================] - 0s 89us/step - loss: 237.6455 - acc: 0.0000e+00 - val_loss: 285.2814 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 228.9256 - acc: 0.0032 - val_loss: 278.6855 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 220.5943 - acc: 0.0000e+00 - val_loss: 269.7627 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 214.4735 - acc: 0.0032 - val_loss: 260.3345 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 207.6166 - acc: 0.0000e+00 - val_loss: 253.9264 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "314/314 [==============================] - 0s 98us/step - loss: 202.3203 - acc: 0.0000e+00 - val_loss: 246.6626 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 196.5824 - acc: 0.0032 - val_loss: 241.8206 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 191.1292 - acc: 0.0032 - val_loss: 233.9065 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 185.8981 - acc: 0.0000e+00 - val_loss: 227.5239 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "314/314 [==============================] - 0s 106us/step - loss: 181.0549 - acc: 0.0032 - val_loss: 223.6514 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "314/314 [==============================] - 0s 86us/step - loss: 176.6623 - acc: 0.0064 - val_loss: 216.1344 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 172.7192 - acc: 0.0064 - val_loss: 210.1161 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 168.1465 - acc: 0.0032 - val_loss: 207.5342 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 164.0776 - acc: 0.0096 - val_loss: 200.5004 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 159.7114 - acc: 0.0032 - val_loss: 196.4429 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 155.6800 - acc: 0.0064 - val_loss: 191.9854 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 152.3635 - acc: 0.0064 - val_loss: 187.1198 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 148.5468 - acc: 0.0064 - val_loss: 183.9275 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 145.3464 - acc: 0.0032 - val_loss: 180.8972 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 142.3388 - acc: 0.0032 - val_loss: 176.2732 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 139.4401 - acc: 0.0032 - val_loss: 171.9593 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 136.4006 - acc: 0.0032 - val_loss: 168.1700 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "314/314 [==============================] - 0s 89us/step - loss: 133.8737 - acc: 0.0032 - val_loss: 165.3517 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 130.5145 - acc: 0.0032 - val_loss: 161.5451 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 128.3658 - acc: 0.0000e+00 - val_loss: 157.4284 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 125.7527 - acc: 0.0032 - val_loss: 156.4260 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "314/314 [==============================] - 0s 97us/step - loss: 123.0868 - acc: 0.0032 - val_loss: 152.6238 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 120.8646 - acc: 0.0032 - val_loss: 148.8426 - val_acc: 0.0400\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 102us/step - loss: 118.2380 - acc: 0.0032 - val_loss: 145.6870 - val_acc: 0.0400\n",
      "Epoch 58/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 115.7177 - acc: 0.0032 - val_loss: 144.8113 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 113.6840 - acc: 0.0032 - val_loss: 139.5821 - val_acc: 0.0400\n",
      "Epoch 60/300\n",
      "314/314 [==============================] - 0s 98us/step - loss: 111.1703 - acc: 0.0032 - val_loss: 137.1583 - val_acc: 0.0400\n",
      "Epoch 61/300\n",
      "314/314 [==============================] - 0s 98us/step - loss: 108.9193 - acc: 0.0032 - val_loss: 135.6982 - val_acc: 0.0400\n",
      "Epoch 62/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 107.4766 - acc: 0.0096 - val_loss: 131.9728 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "314/314 [==============================] - 0s 89us/step - loss: 104.9694 - acc: 0.0064 - val_loss: 130.6388 - val_acc: 0.0400\n",
      "Epoch 64/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 103.4094 - acc: 0.0032 - val_loss: 126.8428 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 100.6776 - acc: 0.0096 - val_loss: 124.9163 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 98.9257 - acc: 0.0064 - val_loss: 122.6191 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 97.7500 - acc: 0.0096 - val_loss: 119.5982 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 95.4494 - acc: 0.0096 - val_loss: 118.8779 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 93.9765 - acc: 0.0064 - val_loss: 115.9621 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "314/314 [==============================] - 0s 89us/step - loss: 92.1962 - acc: 0.0096 - val_loss: 112.9512 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "314/314 [==============================] - 0s 89us/step - loss: 90.2681 - acc: 0.0064 - val_loss: 111.4226 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 89.3361 - acc: 0.0096 - val_loss: 109.4773 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 87.1629 - acc: 0.0064 - val_loss: 107.2198 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 86.3918 - acc: 0.0064 - val_loss: 105.4913 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "314/314 [==============================] - 0s 103us/step - loss: 84.5144 - acc: 0.0032 - val_loss: 103.5204 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 83.0630 - acc: 0.0064 - val_loss: 102.3985 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 81.5949 - acc: 0.0096 - val_loss: 100.3482 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 80.8822 - acc: 0.0064 - val_loss: 99.1110 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 81.6459 - acc: 0.0064 - val_loss: 97.0082 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 78.2659 - acc: 0.0032 - val_loss: 97.3577 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 76.5531 - acc: 0.0064 - val_loss: 94.2012 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 76.0237 - acc: 0.0032 - val_loss: 92.6038 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 74.2580 - acc: 0.0032 - val_loss: 91.4663 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 73.8219 - acc: 0.0096 - val_loss: 90.5088 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 72.3461 - acc: 0.0064 - val_loss: 88.9198 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 71.3604 - acc: 0.0000e+00 - val_loss: 87.6492 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 70.7383 - acc: 0.0032 - val_loss: 86.7973 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 69.5078 - acc: 0.0032 - val_loss: 85.3535 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "314/314 [==============================] - 0s 91us/step - loss: 68.8092 - acc: 0.0000e+00 - val_loss: 84.3242 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 67.8486 - acc: 0.0064 - val_loss: 83.4861 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 67.2020 - acc: 0.0032 - val_loss: 82.2625 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 65.9618 - acc: 0.0064 - val_loss: 81.7659 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 65.5907 - acc: 0.0064 - val_loss: 80.3010 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 64.5911 - acc: 0.0000e+00 - val_loss: 79.5048 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 63.6723 - acc: 0.0064 - val_loss: 78.5594 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 62.9111 - acc: 0.0064 - val_loss: 77.5866 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 62.1869 - acc: 0.0032 - val_loss: 76.8110 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 61.5756 - acc: 0.0064 - val_loss: 76.0991 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "314/314 [==============================] - 0s 89us/step - loss: 63.0937 - acc: 0.0000e+00 - val_loss: 75.5153 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 62.2809 - acc: 0.0159 - val_loss: 76.5558 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 61.2248 - acc: 0.0064 - val_loss: 74.3353 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "314/314 [==============================] - 0s 97us/step - loss: 59.4429 - acc: 0.0064 - val_loss: 73.3679 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 58.8761 - acc: 0.0159 - val_loss: 72.3780 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 58.0530 - acc: 0.0064 - val_loss: 71.6073 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 57.6061 - acc: 0.0000e+00 - val_loss: 71.1200 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 56.6899 - acc: 0.0032 - val_loss: 70.7391 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 56.3367 - acc: 0.0096 - val_loss: 69.9019 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 55.7729 - acc: 0.0064 - val_loss: 69.2011 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 55.3271 - acc: 0.0032 - val_loss: 68.8400 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 54.7667 - acc: 0.0064 - val_loss: 68.2165 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 54.4393 - acc: 0.0096 - val_loss: 67.8079 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 53.8588 - acc: 0.0064 - val_loss: 67.2809 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 53.5183 - acc: 0.0064 - val_loss: 66.6817 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 52.9859 - acc: 0.0064 - val_loss: 66.2419 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 52.5803 - acc: 0.0096 - val_loss: 65.9156 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 52.5928 - acc: 0.0064 - val_loss: 65.5213 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 51.6826 - acc: 0.0032 - val_loss: 65.1107 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 51.4098 - acc: 0.0032 - val_loss: 64.4681 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "314/314 [==============================] - 0s 97us/step - loss: 51.1974 - acc: 0.0096 - val_loss: 64.3067 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 51.1386 - acc: 0.0064 - val_loss: 63.8700 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 50.5290 - acc: 0.0096 - val_loss: 63.6071 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 49.9400 - acc: 0.0096 - val_loss: 62.9190 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 49.5427 - acc: 0.0064 - val_loss: 62.8667 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 49.2876 - acc: 0.0096 - val_loss: 62.4369 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 48.8783 - acc: 0.0127 - val_loss: 62.3173 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 48.9140 - acc: 0.0064 - val_loss: 61.8691 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 48.2004 - acc: 0.0127 - val_loss: 61.5664 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 48.0283 - acc: 0.0064 - val_loss: 61.2919 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 47.7104 - acc: 0.0064 - val_loss: 61.0607 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 47.2750 - acc: 0.0127 - val_loss: 60.7350 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 47.1956 - acc: 0.0127 - val_loss: 60.3783 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "314/314 [==============================] - 0s 89us/step - loss: 46.6967 - acc: 0.0064 - val_loss: 60.1658 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 46.3366 - acc: 0.0096 - val_loss: 59.7556 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 46.4837 - acc: 0.0127 - val_loss: 59.5503 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 46.0441 - acc: 0.0096 - val_loss: 59.5673 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 45.6359 - acc: 0.0127 - val_loss: 59.2985 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "314/314 [==============================] - 0s 88us/step - loss: 45.3453 - acc: 0.0127 - val_loss: 58.8437 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 45.2148 - acc: 0.0064 - val_loss: 58.6259 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 45.0995 - acc: 0.0159 - val_loss: 58.6033 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 44.6698 - acc: 0.0159 - val_loss: 58.7594 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 44.7459 - acc: 0.0064 - val_loss: 58.8136 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 44.0288 - acc: 0.0064 - val_loss: 57.9997 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 44.3339 - acc: 0.0223 - val_loss: 58.4947 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 43.9614 - acc: 0.0064 - val_loss: 57.4335 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 43.3428 - acc: 0.0159 - val_loss: 57.7688 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 43.2452 - acc: 0.0096 - val_loss: 57.2079 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 43.3676 - acc: 0.0127 - val_loss: 57.1583 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 42.8559 - acc: 0.0127 - val_loss: 56.7785 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 42.7828 - acc: 0.0096 - val_loss: 56.9479 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "314/314 [==============================] - 0s 89us/step - loss: 42.5316 - acc: 0.0127 - val_loss: 56.6136 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 42.0380 - acc: 0.0064 - val_loss: 56.5614 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 41.9404 - acc: 0.0159 - val_loss: 56.1468 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 42.2312 - acc: 0.0032 - val_loss: 56.9160 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 42.4567 - acc: 0.0096 - val_loss: 55.8187 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "314/314 [==============================] - 0s 89us/step - loss: 40.9398 - acc: 0.0096 - val_loss: 56.8215 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 41.1803 - acc: 0.0191 - val_loss: 55.9836 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 40.9111 - acc: 0.0159 - val_loss: 55.9504 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 40.9598 - acc: 0.0223 - val_loss: 55.3008 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 40.4223 - acc: 0.0159 - val_loss: 55.6711 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "314/314 [==============================] - 0s 89us/step - loss: 41.0254 - acc: 0.0127 - val_loss: 55.3717 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 40.6037 - acc: 0.0096 - val_loss: 55.3003 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 39.8677 - acc: 0.0127 - val_loss: 54.9898 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 39.8110 - acc: 0.0159 - val_loss: 55.3385 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 39.7852 - acc: 0.0127 - val_loss: 55.5009 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 40.2451 - acc: 0.0159 - val_loss: 54.9808 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 39.3181 - acc: 0.0223 - val_loss: 55.1381 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "314/314 [==============================] - 0s 89us/step - loss: 39.6216 - acc: 0.0127 - val_loss: 55.0090 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 39.0665 - acc: 0.0159 - val_loss: 54.9537 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 38.7865 - acc: 0.0127 - val_loss: 54.7539 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 38.7643 - acc: 0.0127 - val_loss: 54.4707 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 38.7895 - acc: 0.0127 - val_loss: 54.6381 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 90us/step - loss: 39.0499 - acc: 0.0127 - val_loss: 54.3968 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "314/314 [==============================] - 0s 90us/step - loss: 38.1593 - acc: 0.0127 - val_loss: 54.3239 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 38.0960 - acc: 0.0127 - val_loss: 54.2775 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 38.0334 - acc: 0.0127 - val_loss: 54.5091 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "314/314 [==============================] - 0s 97us/step - loss: 37.4687 - acc: 0.0159 - val_loss: 53.8132 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 37.8059 - acc: 0.0127 - val_loss: 54.5855 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 37.2206 - acc: 0.0064 - val_loss: 53.6277 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 37.2505 - acc: 0.0127 - val_loss: 54.7089 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 37.5469 - acc: 0.0127 - val_loss: 53.6415 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 37.4067 - acc: 0.0096 - val_loss: 54.0796 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 36.6522 - acc: 0.0127 - val_loss: 53.4788 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 36.5513 - acc: 0.0159 - val_loss: 53.7186 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "314/314 [==============================] - 0s 89us/step - loss: 36.7186 - acc: 0.0127 - val_loss: 53.4311 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 36.7501 - acc: 0.0096 - val_loss: 54.0706 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 36.1878 - acc: 0.0064 - val_loss: 53.7229 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 36.8167 - acc: 0.0096 - val_loss: 53.5285 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 36.0505 - acc: 0.0096 - val_loss: 53.2136 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 35.8015 - acc: 0.0096 - val_loss: 53.5749 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "314/314 [==============================] - 0s 108us/step - loss: 35.7139 - acc: 0.0064 - val_loss: 53.2839 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "314/314 [==============================] - 0s 115us/step - loss: 35.7125 - acc: 0.0096 - val_loss: 53.3085 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 35.3541 - acc: 0.0096 - val_loss: 53.2107 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "314/314 [==============================] - 0s 108us/step - loss: 35.3231 - acc: 0.0096 - val_loss: 53.4252 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 35.5183 - acc: 0.0127 - val_loss: 53.4607 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "314/314 [==============================] - 0s 108us/step - loss: 34.9972 - acc: 0.0127 - val_loss: 53.1290 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 34.9014 - acc: 0.0096 - val_loss: 52.9023 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 34.5778 - acc: 0.0096 - val_loss: 53.1307 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 35.3116 - acc: 0.0064 - val_loss: 52.7836 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 34.7263 - acc: 0.0096 - val_loss: 52.8408 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 34.4788 - acc: 0.0127 - val_loss: 52.4809 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 34.7465 - acc: 0.0159 - val_loss: 53.5372 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "314/314 [==============================] - 0s 118us/step - loss: 34.3611 - acc: 0.0096 - val_loss: 52.6491 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "314/314 [==============================] - 0s 108us/step - loss: 34.1605 - acc: 0.0064 - val_loss: 53.1955 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 33.9129 - acc: 0.0064 - val_loss: 52.7167 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 33.8895 - acc: 0.0127 - val_loss: 53.5304 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 33.5311 - acc: 0.0127 - val_loss: 52.0222 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 33.5512 - acc: 0.0159 - val_loss: 52.6105 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 33.3587 - acc: 0.0127 - val_loss: 52.7069 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 33.3963 - acc: 0.0159 - val_loss: 52.4618 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "314/314 [==============================] - 0s 137us/step - loss: 33.3643 - acc: 0.0127 - val_loss: 52.3229 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "314/314 [==============================] - 0s 123us/step - loss: 33.3999 - acc: 0.0159 - val_loss: 53.4234 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "314/314 [==============================] - 0s 169us/step - loss: 32.9702 - acc: 0.0191 - val_loss: 52.5935 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "314/314 [==============================] - 0s 130us/step - loss: 33.2550 - acc: 0.0159 - val_loss: 52.1003 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 32.9528 - acc: 0.0064 - val_loss: 52.3232 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "314/314 [==============================] - 0s 107us/step - loss: 33.0029 - acc: 0.0096 - val_loss: 52.7668 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 32.6898 - acc: 0.0096 - val_loss: 52.1679 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 32.4198 - acc: 0.0191 - val_loss: 52.3995 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 32.4746 - acc: 0.0127 - val_loss: 52.1203 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 32.2800 - acc: 0.0064 - val_loss: 52.5958 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 32.5101 - acc: 0.0159 - val_loss: 51.8461 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 32.9074 - acc: 0.0032 - val_loss: 53.5225 - val_acc: 0.0400\n",
      "Epoch 222/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 33.2629 - acc: 0.0064 - val_loss: 52.1179 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "314/314 [==============================] - 0s 130us/step - loss: 32.1391 - acc: 0.0032 - val_loss: 53.1230 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 31.7028 - acc: 0.0096 - val_loss: 52.3746 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 31.9529 - acc: 0.0159 - val_loss: 51.6659 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "314/314 [==============================] - 0s 134us/step - loss: 32.3866 - acc: 0.0096 - val_loss: 52.0338 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "314/314 [==============================] - 0s 185us/step - loss: 31.9591 - acc: 0.0064 - val_loss: 51.9779 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 31.6631 - acc: 0.0127 - val_loss: 52.5291 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 105us/step - loss: 31.9277 - acc: 0.0064 - val_loss: 51.9974 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 31.1794 - acc: 0.0096 - val_loss: 52.4150 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 31.7127 - acc: 0.0064 - val_loss: 52.4268 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 31.8258 - acc: 0.0127 - val_loss: 52.1976 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 31.3614 - acc: 0.0127 - val_loss: 52.3247 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 32.0855 - acc: 0.0000e+00 - val_loss: 51.8050 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 31.4559 - acc: 0.0064 - val_loss: 51.8185 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 31.2710 - acc: 0.0096 - val_loss: 51.9433 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "314/314 [==============================] - 0s 103us/step - loss: 30.7330 - acc: 0.0096 - val_loss: 52.9225 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 31.1529 - acc: 0.0064 - val_loss: 50.9847 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 31.0232 - acc: 0.0032 - val_loss: 53.4419 - val_acc: 0.0400\n",
      "Epoch 240/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 30.1480 - acc: 0.0064 - val_loss: 51.0219 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "314/314 [==============================] - 0s 108us/step - loss: 31.1342 - acc: 0.0032 - val_loss: 53.8987 - val_acc: 0.0400\n",
      "Epoch 242/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 30.3338 - acc: 0.0159 - val_loss: 51.2225 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 31.1966 - acc: 0.0096 - val_loss: 53.0811 - val_acc: 0.0400\n",
      "Epoch 244/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 31.0559 - acc: 0.0032 - val_loss: 51.4313 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 31.3560 - acc: 0.0127 - val_loss: 51.2971 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 32.0265 - acc: 0.0096 - val_loss: 54.3243 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 31.3337 - acc: 0.0064 - val_loss: 50.9015 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 30.0558 - acc: 0.0096 - val_loss: 52.9736 - val_acc: 0.0400\n",
      "Epoch 249/300\n",
      "314/314 [==============================] - 0s 108us/step - loss: 30.3793 - acc: 0.0159 - val_loss: 51.4125 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 30.4301 - acc: 0.0064 - val_loss: 51.0597 - val_acc: 0.0400\n",
      "Epoch 251/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 30.0267 - acc: 0.0032 - val_loss: 51.9916 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 29.7811 - acc: 0.0064 - val_loss: 50.7001 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 30.7002 - acc: 0.0127 - val_loss: 51.3125 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 30.7872 - acc: 0.0096 - val_loss: 51.9252 - val_acc: 0.0400\n",
      "Epoch 255/300\n",
      "314/314 [==============================] - 0s 108us/step - loss: 29.6752 - acc: 0.0032 - val_loss: 50.9471 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 30.5465 - acc: 0.0032 - val_loss: 56.4975 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 30.2769 - acc: 0.0191 - val_loss: 50.5453 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 29.3199 - acc: 0.0096 - val_loss: 52.7692 - val_acc: 0.0400\n",
      "Epoch 259/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 29.8910 - acc: 0.0127 - val_loss: 51.3267 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "314/314 [==============================] - 0s 108us/step - loss: 28.8766 - acc: 0.0096 - val_loss: 52.7884 - val_acc: 0.0400\n",
      "Epoch 261/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 29.3579 - acc: 0.0064 - val_loss: 51.1411 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 29.0312 - acc: 0.0064 - val_loss: 51.7057 - val_acc: 0.0400\n",
      "Epoch 263/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 29.6963 - acc: 0.0064 - val_loss: 50.2064 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 29.1797 - acc: 0.0032 - val_loss: 51.6813 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 28.7929 - acc: 0.0064 - val_loss: 51.4357 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 29.1118 - acc: 0.0064 - val_loss: 51.1048 - val_acc: 0.0400\n",
      "Epoch 267/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 28.6501 - acc: 0.0064 - val_loss: 50.5785 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "314/314 [==============================] - 0s 97us/step - loss: 28.7342 - acc: 0.0032 - val_loss: 51.5744 - val_acc: 0.0400\n",
      "Epoch 269/300\n",
      "314/314 [==============================] - 0s 91us/step - loss: 28.8944 - acc: 0.0064 - val_loss: 52.4985 - val_acc: 0.0400\n",
      "Epoch 270/300\n",
      "314/314 [==============================] - 0s 103us/step - loss: 29.2505 - acc: 0.0000e+00 - val_loss: 50.9467 - val_acc: 0.0400\n",
      "Epoch 271/300\n",
      "314/314 [==============================] - 0s 92us/step - loss: 28.7718 - acc: 0.0064 - val_loss: 50.6738 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 28.7820 - acc: 0.0064 - val_loss: 50.7363 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 28.8404 - acc: 0.0096 - val_loss: 50.8288 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 29.1597 - acc: 0.0064 - val_loss: 52.2847 - val_acc: 0.0400\n",
      "Epoch 275/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 29.1823 - acc: 0.0032 - val_loss: 50.4445 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 28.9169 - acc: 0.0032 - val_loss: 51.0290 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 28.4859 - acc: 0.0064 - val_loss: 51.1651 - val_acc: 0.0400\n",
      "Epoch 278/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 28.4335 - acc: 0.0096 - val_loss: 51.3219 - val_acc: 0.0400\n",
      "Epoch 279/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 28.9127 - acc: 0.0064 - val_loss: 52.6591 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "314/314 [==============================] - 0s 98us/step - loss: 28.6644 - acc: 0.0159 - val_loss: 50.1675 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 28.1362 - acc: 0.0032 - val_loss: 52.3474 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 28.2547 - acc: 0.0064 - val_loss: 51.6631 - val_acc: 0.0400\n",
      "Epoch 283/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 27.8688 - acc: 0.0064 - val_loss: 51.0493 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 28.4226 - acc: 0.0032 - val_loss: 50.2079 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 28.5769 - acc: 0.0032 - val_loss: 51.9677 - val_acc: 0.0400\n",
      "Epoch 286/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 27.7396 - acc: 0.0064 - val_loss: 50.5811 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 102us/step - loss: 28.0133 - acc: 0.0000e+00 - val_loss: 51.3189 - val_acc: 0.0400\n",
      "Epoch 288/300\n",
      "314/314 [==============================] - 0s 96us/step - loss: 28.0822 - acc: 0.0064 - val_loss: 52.7406 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 28.2848 - acc: 0.0032 - val_loss: 51.5838 - val_acc: 0.0400\n",
      "Epoch 290/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 27.6908 - acc: 0.0032 - val_loss: 51.2901 - val_acc: 0.0400\n",
      "Epoch 291/300\n",
      "314/314 [==============================] - 0s 95us/step - loss: 27.7927 - acc: 0.0032 - val_loss: 50.7132 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "314/314 [==============================] - 0s 108us/step - loss: 27.6617 - acc: 0.0064 - val_loss: 51.9344 - val_acc: 0.0400\n",
      "Epoch 293/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 27.6188 - acc: 0.0064 - val_loss: 50.5431 - val_acc: 0.0400\n",
      "Epoch 294/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 27.4575 - acc: 0.0032 - val_loss: 51.1034 - val_acc: 0.0400\n",
      "Epoch 295/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 27.3491 - acc: 0.0032 - val_loss: 51.1969 - val_acc: 0.0400\n",
      "Epoch 296/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 27.6533 - acc: 0.0064 - val_loss: 50.6942 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "314/314 [==============================] - 0s 105us/step - loss: 28.1059 - acc: 0.0096 - val_loss: 52.8434 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "314/314 [==============================] - 0s 99us/step - loss: 28.6965 - acc: 0.0032 - val_loss: 51.5393 - val_acc: 0.0400\n",
      "Epoch 299/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 27.2930 - acc: 0.0032 - val_loss: 50.6300 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "314/314 [==============================] - 0s 102us/step - loss: 27.9926 - acc: 0.0064 - val_loss: 55.5626 - val_acc: 0.0400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab6ace7bc8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle= True)\n",
    "\n",
    "one_hot_train_labels=y_train\n",
    "one_hot_test_labels=y_test\n",
    "\n",
    "x_val=x_train[:25]\n",
    "partial_x_train=x_train[25:]\n",
    "\n",
    "y_val=one_hot_train_labels[:25]\n",
    "partial_y_train=one_hot_train_labels[25:]\n",
    "\n",
    "import keras\n",
    "inputs= keras.Input(shape=(13,))\n",
    "x=Dense(32,activation='relu')(inputs)\n",
    "outputs=Dense(1)(x) \n",
    "model=keras.Model(inputs,outputs)\n",
    "model.compile(optimizer='Adam',loss='mean_squared_error',metrics=['accuracy'])    \n",
    "model.fit(partial_x_train,partial_y_train,epochs=300,validation_data=(x_val,y_val))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 314 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "314/314 [==============================] - 3s 11ms/step - loss: 5167.3078 - acc: 0.0000e+00 - val_loss: 1430.7905 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 2022.5117 - acc: 0.0000e+00 - val_loss: 827.9525 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 1398.2720 - acc: 0.0032 - val_loss: 579.1267 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 1028.0898 - acc: 0.0032 - val_loss: 414.4481 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 748.2925 - acc: 0.0000e+00 - val_loss: 302.6448 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "314/314 [==============================] - 0s 103us/step - loss: 566.7710 - acc: 0.0159 - val_loss: 256.8471 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 430.0709 - acc: 0.0096 - val_loss: 209.6244 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "314/314 [==============================] - 0s 101us/step - loss: 334.5581 - acc: 0.0096 - val_loss: 193.2142 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 257.3827 - acc: 0.0127 - val_loss: 172.2349 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 193.9736 - acc: 0.0064 - val_loss: 131.3874 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "314/314 [==============================] - 0s 89us/step - loss: 156.2874 - acc: 0.0000e+00 - val_loss: 107.8767 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 132.5627 - acc: 0.0064 - val_loss: 92.3035 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "314/314 [==============================] - 0s 90us/step - loss: 106.5497 - acc: 0.0096 - val_loss: 87.1334 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "314/314 [==============================] - 0s 96us/step - loss: 90.0972 - acc: 0.0064 - val_loss: 76.7519 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "314/314 [==============================] - 0s 89us/step - loss: 77.3337 - acc: 0.0032 - val_loss: 70.5904 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 78.1152 - acc: 0.0032 - val_loss: 67.6764 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "314/314 [==============================] - 0s 96us/step - loss: 65.0380 - acc: 0.0032 - val_loss: 79.1614 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "314/314 [==============================] - 0s 93us/step - loss: 67.0054 - acc: 0.0064 - val_loss: 76.7409 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 59.2321 - acc: 0.0032 - val_loss: 67.8880 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "314/314 [==============================] - 0s 95us/step - loss: 66.4737 - acc: 0.0096 - val_loss: 71.9919 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "314/314 [==============================] - 0s 95us/step - loss: 58.3143 - acc: 0.0064 - val_loss: 61.8669 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 51.7087 - acc: 0.0096 - val_loss: 56.7995 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "314/314 [==============================] - 0s 95us/step - loss: 55.3538 - acc: 0.0000e+00 - val_loss: 58.0036 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "314/314 [==============================] - 0s 96us/step - loss: 54.5114 - acc: 0.0064 - val_loss: 70.0550 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 55.1518 - acc: 0.0000e+00 - val_loss: 71.3278 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "314/314 [==============================] - 0s 95us/step - loss: 57.5091 - acc: 0.0096 - val_loss: 64.0123 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 55.3175 - acc: 0.0032 - val_loss: 77.9269 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 49.8277 - acc: 0.0000e+00 - val_loss: 87.1942 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 50.8899 - acc: 0.0032 - val_loss: 57.7037 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "314/314 [==============================] - 0s 94us/step - loss: 56.1928 - acc: 0.0064 - val_loss: 51.7436 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "314/314 [==============================] - 0s 103us/step - loss: 45.1945 - acc: 0.0000e+00 - val_loss: 59.6870 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "314/314 [==============================] - 0s 101us/step - loss: 45.7565 - acc: 0.0064 - val_loss: 54.4709 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 52.5890 - acc: 0.0064 - val_loss: 60.8014 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 46.4938 - acc: 0.0064 - val_loss: 57.8344 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 42.4106 - acc: 0.0032 - val_loss: 57.7631 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 55.4727 - acc: 0.0096 - val_loss: 61.9459 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 42.3762 - acc: 0.0064 - val_loss: 58.8402 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "314/314 [==============================] - 0s 96us/step - loss: 46.6149 - acc: 0.0032 - val_loss: 51.4327 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 46.4191 - acc: 0.0096 - val_loss: 51.7638 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 43.6310 - acc: 0.0032 - val_loss: 53.4745 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "314/314 [==============================] - 0s 93us/step - loss: 43.7494 - acc: 0.0064 - val_loss: 100.7151 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "314/314 [==============================] - 0s 95us/step - loss: 50.8605 - acc: 0.0127 - val_loss: 47.6694 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 40.9860 - acc: 0.0032 - val_loss: 79.4426 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "314/314 [==============================] - 0s 95us/step - loss: 43.8787 - acc: 0.0127 - val_loss: 58.0135 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "314/314 [==============================] - 0s 95us/step - loss: 48.9171 - acc: 0.0032 - val_loss: 50.7879 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 40.9775 - acc: 0.0064 - val_loss: 47.3375 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 38.5728 - acc: 0.0064 - val_loss: 48.4838 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "314/314 [==============================] - 0s 105us/step - loss: 43.1998 - acc: 0.0032 - val_loss: 47.2099 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "314/314 [==============================] - 0s 105us/step - loss: 37.1323 - acc: 0.0032 - val_loss: 51.9947 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 46.8140 - acc: 0.0032 - val_loss: 84.5342 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 42.4348 - acc: 0.0032 - val_loss: 72.1890 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 44.8469 - acc: 0.0032 - val_loss: 51.6267 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 37.5230 - acc: 0.0000e+00 - val_loss: 49.5996 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "314/314 [==============================] - 0s 100us/step - loss: 36.7968 - acc: 0.0032 - val_loss: 75.2291 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "314/314 [==============================] - 0s 94us/step - loss: 42.7131 - acc: 0.0000e+00 - val_loss: 53.8403 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "314/314 [==============================] - 0s 95us/step - loss: 41.9520 - acc: 0.0064 - val_loss: 48.7993 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 44.1448 - acc: 0.0032 - val_loss: 81.4106 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 92us/step - loss: 39.1812 - acc: 0.0096 - val_loss: 45.5802 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "314/314 [==============================] - 0s 89us/step - loss: 38.1234 - acc: 0.0064 - val_loss: 56.3152 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "314/314 [==============================] - 0s 94us/step - loss: 42.4483 - acc: 0.0032 - val_loss: 48.3327 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 35.7482 - acc: 0.0127 - val_loss: 48.5916 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 36.8280 - acc: 0.0127 - val_loss: 50.8672 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 42.4761 - acc: 0.0000e+00 - val_loss: 61.3621 - val_acc: 0.0400\n",
      "Epoch 64/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 34.2788 - acc: 0.0096 - val_loss: 55.5559 - val_acc: 0.0400\n",
      "Epoch 65/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 37.2568 - acc: 0.0032 - val_loss: 58.4511 - val_acc: 0.0400\n",
      "Epoch 66/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 45.3551 - acc: 0.0064 - val_loss: 49.9526 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "314/314 [==============================] - 0s 94us/step - loss: 34.3067 - acc: 0.0127 - val_loss: 62.1727 - val_acc: 0.0400\n",
      "Epoch 68/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 41.0785 - acc: 0.0032 - val_loss: 48.7198 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "314/314 [==============================] - 0s 89us/step - loss: 33.9841 - acc: 0.0096 - val_loss: 48.9054 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 35.4930 - acc: 0.0032 - val_loss: 50.5513 - val_acc: 0.0400\n",
      "Epoch 71/100\n",
      "314/314 [==============================] - 0s 101us/step - loss: 38.7271 - acc: 0.0000e+00 - val_loss: 45.6375 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 39.2082 - acc: 0.0032 - val_loss: 46.5827 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "314/314 [==============================] - 0s 95us/step - loss: 32.9614 - acc: 0.0032 - val_loss: 55.3784 - val_acc: 0.0400\n",
      "Epoch 74/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 38.8526 - acc: 0.0064 - val_loss: 59.6452 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "314/314 [==============================] - 0s 85us/step - loss: 36.2139 - acc: 0.0064 - val_loss: 45.8451 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "314/314 [==============================] - 0s 89us/step - loss: 39.3659 - acc: 0.0096 - val_loss: 58.7822 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 32.7463 - acc: 0.0096 - val_loss: 49.6411 - val_acc: 0.0400\n",
      "Epoch 78/100\n",
      "314/314 [==============================] - 0s 95us/step - loss: 44.8936 - acc: 0.0127 - val_loss: 49.6714 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "314/314 [==============================] - 0s 95us/step - loss: 33.8403 - acc: 0.0064 - val_loss: 52.7143 - val_acc: 0.0800\n",
      "Epoch 80/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 39.1306 - acc: 0.0032 - val_loss: 47.6738 - val_acc: 0.0400\n",
      "Epoch 81/100\n",
      "314/314 [==============================] - 0s 99us/step - loss: 33.1591 - acc: 0.0000e+00 - val_loss: 50.8862 - val_acc: 0.0400\n",
      "Epoch 82/100\n",
      "314/314 [==============================] - 0s 91us/step - loss: 38.7385 - acc: 0.0064 - val_loss: 60.6385 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 35.0226 - acc: 0.0032 - val_loss: 93.5915 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 36.4286 - acc: 0.0000e+00 - val_loss: 67.4676 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "314/314 [==============================] - 0s 96us/step - loss: 35.2608 - acc: 0.0064 - val_loss: 65.1487 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "314/314 [==============================] - 0s 96us/step - loss: 37.2207 - acc: 0.0096 - val_loss: 54.5152 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "314/314 [==============================] - 0s 89us/step - loss: 40.0986 - acc: 0.0032 - val_loss: 53.4185 - val_acc: 0.0400\n",
      "Epoch 88/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 32.0458 - acc: 0.0000e+00 - val_loss: 47.9013 - val_acc: 0.0400\n",
      "Epoch 89/100\n",
      "314/314 [==============================] - 0s 108us/step - loss: 38.2676 - acc: 0.0127 - val_loss: 48.7661 - val_acc: 0.0400\n",
      "Epoch 90/100\n",
      "314/314 [==============================] - 0s 105us/step - loss: 33.5393 - acc: 0.0064 - val_loss: 51.6486 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "314/314 [==============================] - 0s 102us/step - loss: 31.1481 - acc: 0.0096 - val_loss: 72.4327 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 34.8970 - acc: 0.0064 - val_loss: 55.8177 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "314/314 [==============================] - 0s 96us/step - loss: 39.8106 - acc: 0.0096 - val_loss: 59.0359 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "314/314 [==============================] - 0s 89us/step - loss: 37.0302 - acc: 0.0064 - val_loss: 54.8620 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "314/314 [==============================] - 0s 89us/step - loss: 35.7152 - acc: 0.0000e+00 - val_loss: 51.3838 - val_acc: 0.0800\n",
      "Epoch 96/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 32.4511 - acc: 0.0064 - val_loss: 79.5854 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "314/314 [==============================] - 0s 92us/step - loss: 37.0728 - acc: 0.0096 - val_loss: 45.5716 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "314/314 [==============================] - 0s 95us/step - loss: 33.6346 - acc: 0.0064 - val_loss: 57.8536 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "314/314 [==============================] - 0s 89us/step - loss: 34.4053 - acc: 0.0064 - val_loss: 46.8639 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "314/314 [==============================] - 0s 95us/step - loss: 37.0805 - acc: 0.0064 - val_loss: 53.5450 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.dense1=Dense(32,activation='relu')\n",
    "        \n",
    "        self.dense3=Dense(1)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        x=self.dense1(inputs)\n",
    "        \n",
    "        return self.dense3(x)\n",
    "model=MyModel()\n",
    "model.compile(optimizer='rmsprop',loss='mean_squared_error',metrics=['accuracy'])    \n",
    "history=model.fit(partial_x_train,partial_y_train,epochs=100,validation_data=(x_val,y_val))\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/15\n",
      "380/380 [==============================] - 4s 10ms/step - loss: 1468.4561 - acc: 0.0132\n",
      "Epoch 2/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 75.4353 - acc: 0.0105\n",
      "Epoch 3/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 67.7148 - acc: 0.0053\n",
      "Epoch 4/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 62.5686 - acc: 0.0079\n",
      "Epoch 5/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 59.6057 - acc: 0.0053\n",
      "Epoch 6/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 56.3704 - acc: 0.0211\n",
      "Epoch 7/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 53.2540 - acc: 0.0132\n",
      "Epoch 8/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 57.7625 - acc: 0.0053\n",
      "Epoch 9/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 53.8476 - acc: 0.0053\n",
      "Epoch 10/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 53.8473 - acc: 0.0105\n",
      "Epoch 11/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 54.9138 - acc: 0.0105\n",
      "Epoch 12/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 52.9476 - acc: 0.0026\n",
      "Epoch 13/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 49.3711 - acc: 0.0105\n",
      "Epoch 14/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 53.2508 - acc: 0.0053\n",
      "Epoch 15/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 51.4717 - acc: 0.0132\n",
      "126/126 [==============================] - 1s 10ms/step\n",
      "processing fold # 1\n",
      "Epoch 1/15\n",
      "380/380 [==============================] - 4s 10ms/step - loss: 276.5059 - acc: 0.0079\n",
      "Epoch 2/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 60.2507 - acc: 0.0105\n",
      "Epoch 3/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 55.5128 - acc: 0.0053\n",
      "Epoch 4/15\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 46.8811 - acc: 0.0053\n",
      "Epoch 5/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 47.2510 - acc: 0.0053\n",
      "Epoch 6/15\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 45.9436 - acc: 0.0105\n",
      "Epoch 7/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 44.5176 - acc: 0.0079\n",
      "Epoch 8/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 43.7457 - acc: 0.0105\n",
      "Epoch 9/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 41.9303 - acc: 0.0026\n",
      "Epoch 10/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 40.4881 - acc: 0.0105\n",
      "Epoch 11/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 40.1417 - acc: 0.0079\n",
      "Epoch 12/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 41.6090 - acc: 0.0026\n",
      "Epoch 13/15\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 41.0651 - acc: 0.0053\n",
      "Epoch 14/15\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 37.3408 - acc: 0.0105\n",
      "Epoch 15/15\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 40.3741 - acc: 0.0105\n",
      "126/126 [==============================] - 1s 10ms/step\n",
      "processing fold # 2\n",
      "Epoch 1/15\n",
      "380/380 [==============================] - 4s 10ms/step - loss: 420.2055 - acc: 0.0105\n",
      "Epoch 2/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 63.9247 - acc: 0.0079\n",
      "Epoch 3/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 53.5651 - acc: 0.0105\n",
      "Epoch 4/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 48.6916 - acc: 0.0105\n",
      "Epoch 5/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 43.8415 - acc: 0.0053\n",
      "Epoch 6/15\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 44.8551 - acc: 0.0053\n",
      "Epoch 7/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 42.2616 - acc: 0.0237\n",
      "Epoch 8/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 42.5905 - acc: 0.0184\n",
      "Epoch 9/15\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 40.9186 - acc: 0.0105\n",
      "Epoch 10/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 40.0091 - acc: 0.0026\n",
      "Epoch 11/15\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 41.2741 - acc: 0.0184\n",
      "Epoch 12/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 37.5672 - acc: 0.0105\n",
      "Epoch 13/15\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 38.9686 - acc: 0.0132\n",
      "Epoch 14/15\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 37.9973 - acc: 0.0158\n",
      "Epoch 15/15\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 37.6784 - acc: 0.0158\n",
      "126/126 [==============================] - 1s 10ms/step\n",
      "processing fold # 3\n",
      "Epoch 1/15\n",
      "380/380 [==============================] - 4s 10ms/step - loss: 2961.1354 - acc: 0.0053\n",
      "Epoch 2/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 96.5577 - acc: 0.0079\n",
      "Epoch 3/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 74.8873 - acc: 0.0053\n",
      "Epoch 4/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 63.7379 - acc: 0.0079\n",
      "Epoch 5/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 58.0319 - acc: 0.0132\n",
      "Epoch 6/15\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 53.9926 - acc: 0.0105\n",
      "Epoch 7/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 51.7835 - acc: 0.0158\n",
      "Epoch 8/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 49.1125 - acc: 0.0026\n",
      "Epoch 9/15\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 47.4265 - acc: 0.0184\n",
      "Epoch 10/15\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 46.3607 - acc: 0.0079\n",
      "Epoch 11/15\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 47.5688 - acc: 0.0079\n",
      "Epoch 12/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 48.3203 - acc: 0.0053\n",
      "Epoch 13/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 46.4034 - acc: 0.0079\n",
      "Epoch 14/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 44.4248 - acc: 0.0158\n",
      "Epoch 15/15\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 45.7714 - acc: 0.0026\n",
      "126/126 [==============================] - 1s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "k=4\n",
    "num_val_samples=len(X)//k\n",
    "num_epochs=15\n",
    "all_scores=[]\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = X[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = Y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = numpy.concatenate([X[:i * num_val_samples],\n",
    "    X[(i + 1) * num_val_samples:]],\n",
    "    axis=0)\n",
    "    partial_train_targets = numpy.concatenate(\n",
    "    [Y[:i * num_val_samples],\n",
    "    Y[(i + 1) * num_val_samples:]],\n",
    "    axis=0)\n",
    "    model = tuned_model()\n",
    "    model.fit(partial_train_data, partial_train_targets,\n",
    "    epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=1)\n",
    "    all_scores.append(val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.397775562982716"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores\n",
    "numpy.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
